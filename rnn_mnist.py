# -*- coding: utf-8 -*-
"""rnn_mnist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18qT6sCubdzKsTZmxbsA5uY8phPklRT-t
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
print(tf.__version__)

from tensorflow.keras.layers import Input, LSTM, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Model

import numpy as np
import matplotlib.pyplot as plt

fashion_mnist = tf.keras.datasets.fashion_mnist

(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()

x_train = x_train/255
x_test = x_test/255

print("x_train.shape",x_train.shape)
print("y_train.shape",y_train.shape)

x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)

print("x_train.shape",x_train.shape)
print("x_test.shape",x_test.shape)

x_train = np.squeeze(x_train,-1)
x_test = np.squeeze(x_test,-1)

print("x_train.shape",x_train.shape)
print("x_test.shape",x_test.shape)

K = len(set(y_train))
print("number of classes : ",K)

i = Input(shape = x_train[0].shape)
x = LSTM(128)(i)
x = Dense(10,activation='softmax')(x)

model = Model(i,x)

model.compile(optimizer=Adam(0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])
r = model.fit(x_train, y_train, epochs=10, validation_data=(x_test,y_test))

plt.plot(r.history['loss'],label='loss')
plt.plot(r.history['val_loss'],label='val_loss')
plt.legend()

plt.plot(r.history['accuracy'],label='acc')
plt.plot(r.history['val_accuracy'],label='val_acc')
plt.legend()